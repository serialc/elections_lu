{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "6f9988ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# get the the main page for a list of communes\n",
    "url_root = \"https://elections.public.lu\"\n",
    "# specify the year\n",
    "year = \"2018\"\n",
    "\n",
    "r = requests.get(url_root + \"/fr/elections-legislatives/\" + year + \"/resultats.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4c7727",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "cd2575df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the good parts with the name and url of each commune\n",
    "soup = BeautifulSoup(r.text, 'html.parser')\n",
    "\n",
    "coms = soup.find(id=\"communes\").find_all(\"li\", class_=\"town\")\n",
    "    \n",
    "com_results = {}\n",
    "\n",
    "for com in coms:\n",
    "    #print(com.prettify())\n",
    "    com_name = com.a.text\n",
    "    com_url  = url_root + com.a['href']\n",
    "    \n",
    "    com_results[com_name] = {\"url\": com_url}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df046abb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "b1b8a2f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beaufort\n",
      "Bech\n",
      "Beckerich\n",
      "Berdorf\n",
      "Bertrange\n",
      "Bettembourg\n",
      "Bettendorf\n",
      "Betzdorf\n",
      "Bissen\n",
      "Biwer\n",
      "Boulaide\n",
      "Bourscheid\n",
      "Bous\n",
      "Clervaux\n",
      "Colmar-Berg\n",
      "Consdorf\n",
      "Contern\n",
      "Dalheim\n",
      "Diekirch\n",
      "Differdange\n",
      "Dippach\n",
      "Dudelange\n",
      "Echternach\n",
      "Ell\n",
      "Erpeldange-sur-Sûre\n",
      "Esch-sur-Alzette\n",
      "Esch-sur-Sûre\n",
      "Ettelbruck\n",
      "Feulen\n",
      "Fischbach\n",
      "Flaxweiler\n",
      "Frisange\n",
      "Garnich\n",
      "Goesdorf\n",
      "Grevenmacher\n",
      "Grosbous\n",
      "Habscht\n",
      "Heffingen\n",
      "Helperknapp\n",
      "Hesperange\n",
      "Junglinster\n",
      "Käerjeng\n",
      "Kayl\n",
      "Kehlen\n",
      "Kiischpelt\n",
      "Koerich\n",
      "Kopstal\n",
      "Lac de la Haute-Sûre\n",
      "Larochette\n",
      "Lenningen\n",
      "Leudelange\n",
      "Lintgen\n",
      "Lorentzweiler\n",
      "Luxembourg\n",
      "Mamer\n",
      "Manternach\n",
      "Mersch\n",
      "Mertert\n",
      "Mertzig\n",
      "Mondercange\n",
      "Mondorf-les-Bains\n",
      "Niederanven\n",
      "Nommern\n",
      "Parc Hosingen\n",
      "Pétange\n",
      "Préizerdaul\n",
      "Putscheid\n",
      "Rambrouch\n",
      "Reckange-sur-Mess\n",
      "Redange/Attert\n",
      "Reisdorf\n",
      "Remich\n",
      "Roeser\n",
      "Rosport-Mompach\n",
      "Rumelange\n",
      "Saeul\n",
      "Sandweiler\n",
      "Sanem\n",
      "Schengen\n",
      "Schieren\n",
      "Schifflange\n",
      "Schuttrange\n",
      "Stadtbredimus\n",
      "Steinfort\n",
      "Steinsel\n",
      "Strassen\n",
      "Tandel\n",
      "Troisvierges\n",
      "Useldange\n",
      "Vallée de l'Ernz\n",
      "Vianden\n",
      "Vichten\n",
      "Wahl\n",
      "Waldbillig\n",
      "Waldbredimus\n",
      "Walferdange\n",
      "Weiler-la-Tour\n",
      "Weiswampach\n",
      "Wiltz\n",
      "Wincrange\n",
      "Winseler\n",
      "Wormeldange\n"
     ]
    }
   ],
   "source": [
    "party_names_list = []\n",
    "\n",
    "# Go through each commune\n",
    "for com_name in com_results:\n",
    "    print(com_name)\n",
    "    \n",
    "    # 'pass' by reference\n",
    "    com = com_results[com_name]\n",
    "\n",
    "    # get the page\n",
    "    cr = requests.get(com['url'])\n",
    "    csoup = BeautifulSoup(cr.text, 'html.parser')\n",
    "\n",
    "    cresults = csoup.find(\"section\", id=\"results\")\n",
    "    # get the commune's election results (cer)\n",
    "    cer_subtable = cresults.find_all(\"tbody\", class_=\"suffrages-parti\")\n",
    "\n",
    "    com[\"Results\"] = {}\n",
    "    \n",
    "    # cer_subtable length is equal to the number of parties in the commune    \n",
    "    for party_res in cer_subtable:\n",
    "        party_name = party_res.find(class_=\"suffrages-parti-name\").text\n",
    "        \n",
    "        if party_name not in party_names_list:\n",
    "            party_names_list.append(party_name)\n",
    "        \n",
    "        # We will only retrieve the first row that contains the totals\n",
    "        # for the party, not the individual breakdown per candidate\n",
    "        # see party_res.find_all(\"tr\")[1]\n",
    "        p_values = party_res.find_all(\"tr\")[0].find_all(\"td\")\n",
    "        votes_list = int(p_values[0].text.replace(' ', ''))\n",
    "        votes_candidate = int(p_values[1].text.replace(' ', ''))\n",
    "        votes_total = int(p_values[2].text.replace(' ', ''))\n",
    "\n",
    "        com[\"Results\"][party_name] = {\"vot_list\": votes_list, \"vot_cand\": votes_candidate, \"vot_total\": votes_total}\n",
    "    \n",
    "    # go through each section of the statistics\n",
    "    for data_section in csoup.find_all(\"div\", class_=\"lux-number\"):\n",
    "        heading = data_section.h3.text\n",
    "\n",
    "        if heading == \"Bureaux\":\n",
    "            stats = data_section.find_all(\"li\")\n",
    "            \n",
    "            ps_count = int(stats[0].span.text.replace(' ', ''))\n",
    "            ps_lv_only = int(stats[1].span.text.replace(' ', ''))\n",
    "            ps_complete = int(stats[1].span.text.replace(' ', ''))\n",
    "\n",
    "            com[heading] = {\"ps_count\": ps_count, \"ps_lv_only\": ps_lv_only, \"ps_complete\": ps_complete}\n",
    "\n",
    "        if heading == \"Candidats\":\n",
    "            stats = data_section.find_all(\"li\")\n",
    "\n",
    "            cand_total = int(stats[0].span.text.replace(' ', ''))\n",
    "            cand_women = int(stats[1].span.text.replace(' ', ''))\n",
    "            cand_men = int(stats[2].span.text.replace(' ', ''))\n",
    "\n",
    "            com[heading] = {\"cand_women\": cand_women, \"cand_men\": cand_men, \"cand_total\": cand_total}\n",
    "\n",
    "        if heading == \"Electeurs\":\n",
    "            stats = data_section.find_all(\"li\")\n",
    "            \n",
    "            el_registered = int(stats[0].span.text.replace(' ', ''))\n",
    "            \n",
    "            # next item is present in 2023, not 2018, and ...\n",
    "            if len(stats) > 1:\n",
    "                el_postal_ballots = int(stats[1].span.text.replace(' ', ''))\n",
    "            else:\n",
    "                el_postal_ballots = -999\n",
    "            \n",
    "            com[heading] = {\"el_registered\": el_registered, \"el_postal_ballots\": el_postal_ballots}\n",
    "\n",
    "        if heading == \"Bulletins\":\n",
    "            stats = data_section.find_all(\"li\")\n",
    "\n",
    "            bl_in_box = int(stats[0].span.text.replace(' ', ''))\n",
    "            bl_valid = int(stats[1].span.text.replace(' ', ''))\n",
    "            bl_blank = int(stats[2].span.text.replace(' ', ''))\n",
    "            bl_invalid = int(stats[3].span.text.replace(' ', ''))\n",
    "            bl_postal = int(stats[4].span.text.replace(' ', ''))\n",
    "\n",
    "            com[heading] = {\"bl_in_box\": bl_in_box, \"bl_valid\": bl_valid, \"bl_blank\": bl_blank,\n",
    "                            \"bl_invalid\": bl_invalid, \"bl_postal\": bl_postal}\n",
    "\n",
    "        if heading == \"Suffrages\":\n",
    "            stats = data_section.find_all(\"li\")\n",
    "\n",
    "            vot_count = int(stats[0].span.text.replace(' ', ''))\n",
    "            vot_total_cast = int(stats[1].span.text.replace(' ', ''))\n",
    "\n",
    "            com[heading] = {\"vot_count\": vot_count, \"vot_total_cast\": vot_total_cast}\n",
    "            \n",
    "        # end of sections\n",
    "        \n",
    "    # end of commune\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147bd6bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "27ef180a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data in JSON format\n",
    "import json\n",
    "\n",
    "json_object = json.dumps(com_results, indent=4)\n",
    "with open(\"data/\" + year + \"_legislative_election_results.json\", \"w\") as fh:\n",
    "    fh.write(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca30c381",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "26ebd14e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save data in CSV format\n",
    "with open(\"data/\" + year + \"_legislative_election_results.csv\", \"w\") as fh:\n",
    "    #print(com_results)\n",
    "    header = True\n",
    "    headerline = [\"com_name\"]\n",
    "    \n",
    "    for com_name in com_results:\n",
    "        # remove the source URL\n",
    "        if 'url' in com_results[com_name]:\n",
    "            del com_results[com_name]['url']\n",
    "\n",
    "        combined = [com_name]\n",
    "        for section in com_results[com_name]:\n",
    "            if header:\n",
    "                headerline += com_results[com_name][section]\n",
    "                \n",
    "            # need to handle with care, make sure party values are correctly aligned\n",
    "            if section == \"Results\":\n",
    "                for pname in party_names_list:\n",
    "                    if pname in com_results[com_name][section]:\n",
    "                        combined.append(com_results[com_name][section][pname][\"vot_total\"])\n",
    "                    else:\n",
    "                        combined.append(0)\n",
    "            else:\n",
    "                combined += com_results[com_name][section].values()\n",
    "            \n",
    "        # write header\n",
    "        if header:\n",
    "            header = False\n",
    "            fh.write(','.join(headerline) + '\\n')\n",
    "        \n",
    "        # write line of data\n",
    "        fh.write(','.join(str(x) for x in combined) + '\\n')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
